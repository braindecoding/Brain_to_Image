{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timta\\Documents\\Msc Notes\\CMP9140-2324 Research Project\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import seaborn as sns\n",
    "from keras.utils import to_categorical\n",
    "from scipy.integrate import simps\n",
    "from scipy.signal import butter, filtfilt, iirnotch, welch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Brain_to_Image import batch_csv as batch\n",
    "from Brain_to_Image import helper_functions as hf\n",
    "from Brain_to_Image.dataset_formats import (MDB2022_MNIST_EP_params,\n",
    "                                            MDB2022_MNIST_IN_params,\n",
    "                                            MDB2022_MNIST_MU_params,\n",
    "                                            keys_MNIST_EP, keys_MNIST_IN,\n",
    "                                            keys_MNIST_MU)\n",
    "\n",
    "#%matplotlib widget\n",
    "sns.set(font_scale=1.2)\n",
    "print(os.getcwd())\n",
    "\n",
    "dataset = \"MNIST_EP\"\n",
    "root_dir = f\"Datasets/MindBigData MNIST of Brain Digits/{dataset}\"\n",
    "if True:\n",
    "    # ## TRAIN\n",
    "    input_file = f\"train_MindBigData2022_{dataset}.csv\"\n",
    "    output_file = f\"train_MindBigData2022_{dataset}.pkl\"\n",
    "else:\n",
    "    ## TEST\n",
    "    input_file = f\"test_MindBigData2022_{dataset}.csv\"\n",
    "    output_file = f\"test_MindBigData2022_{dataset}.pkl\"\n",
    "\n",
    "label = 'digit_label'\n",
    "## MNIST_MU sf = 220, 440 samples , MNIST_EP sf = 128, 256 samples , MNIST_IN sf = 128, 256 samples\n",
    "if \"_EP\" in dataset or \"_IN\" in dataset:\n",
    "    sample_rate = 128  #Hz\n",
    "else:\n",
    "    sample_rate = 220  #Hz\n",
    "# Define notch frequencies and widths\n",
    "notch_freqs = [50] #, 60]  # Line noise frequencies (50 Hz and harmonics)\n",
    "notch_widths = [1] #, 2]  # Notch widths (in Hz)\n",
    "# Define filter parameters\n",
    "lowcut = 0.4 # 0.4  # Low-cutoff frequency (Hz)\n",
    "highcut = 60 # 110  # High-cutoff frequency (Hz)\n",
    "class_labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "keys_ = ['EEGdata_T7','EEGdata_P7','EEGdata_T8','EEGdata_P8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MBD2022 data set raw csv files are loaded and processed into pandas dataframes and saved as pickle format.\n",
    "- one time process to make data more accessible for use in other processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the raw data file from the hugging face download site.\n",
    "# df = batch.batch_process_csv_pandas(f\"{root_dir}/{input_file}\",f\"{root_dir}/{output_file}\",MBD=MDB2022_MNIST_EP_params)\n",
    "# df.info()\n",
    "# df['digit_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this block to read the raw data from pandas pickle file or insert filtered_ prefix to read filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Raw\n",
    "if True:\n",
    "    print(f\"** reading file {root_dir}/{output_file}\")\n",
    "    df = pd.read_pickle(f\"{root_dir}/{output_file}\")\n",
    "    df = df[df[label]!=-1]\n",
    "    df.info()\n",
    "    print(df[label].value_counts())\n",
    "## Filtered\n",
    "if False:\n",
    "    print(f\"** reading file {root_dir}/filtered_bp_corr_{output_file}\") #filtered_{output_file}\")\n",
    "    df = pd.read_pickle(f\"{root_dir}/filtered_bp_corr_{output_file}\") #filtered_{output_file}\")\n",
    "    df = df[df[label]!=-1]\n",
    "    df.info()\n",
    "    print(df[label].value_counts())\n",
    "    print(df.columns)\n",
    "\n",
    "if False:\n",
    "    features = np.load(f\"{root_dir}/training_{dataset}_corr_93_signals.npy\")\n",
    "    labels = np.load(f\"{root_dir}/training_{dataset}_corr_93_signals_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"** reading file {root_dir}/mne_epoch_rejection_idx.pkl\")\n",
    "epoched_indexs = pd.read_pickle(f\"{root_dir}/mne_epoch_rejection_idx.pkl\")\n",
    "df = df.loc[epoched_indexs['passed']]\n",
    "print(df[label].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for sampling from the total data:\n",
    "- remove the -1 labelled data which is the blank image\n",
    "- groupby the lable\n",
    "- sample using the fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 1\n",
    "sampled_indexes = df.groupby(label).apply(lambda x: x.sample(frac=fraction)).index.get_level_values(1).tolist()\n",
    "sampled_df = df.loc[sampled_indexes]\n",
    "#sampled_df.info()\n",
    "df = None\n",
    "print(sampled_df[label].value_counts())\n",
    "print(sampled_df[label].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to Create windowed data based on window 32, overlap 4 = step size 28\n",
    "def sliding_window_eeg(signal, window_size=32, overlap=4):\n",
    "    \"\"\"\n",
    "    Apply a sliding window with overlap to a 2-second EEG signal.\n",
    "\n",
    "    Parameters:\n",
    "    signal (numpy.ndarray): 1D array of EEG signal data (256 samples)\n",
    "    window_size (int): Size of each window (default: 32)\n",
    "    overlap (int): Number of overlapping samples between windows (default: 4)\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: 2D array of windowed data\n",
    "    \"\"\"\n",
    "    if len(signal) != 256:\n",
    "        raise ValueError(\"Signal length must be 256 samples (2 seconds at 128Hz)\")\n",
    "\n",
    "    # Calculate the step size\n",
    "    step = window_size - overlap\n",
    "\n",
    "    # Calculate the number of windows\n",
    "    num_windows = (len(signal) - window_size) // step + 1\n",
    "\n",
    "    # Create an empty array to store the windowed data\n",
    "    windowed_data = np.zeros((num_windows, window_size, 1))\n",
    "\n",
    "    # Apply the sliding window\n",
    "    for i in range(num_windows):\n",
    "        start = i * step\n",
    "        end = start + window_size\n",
    "        windowed_data[i] = signal[start:end].reshape(window_size,1)\n",
    "    return windowed_data\n",
    "\n",
    "# w_data = sliding_window_eeg(df[df[label]==3].iloc[4]['EEGdata_AF3'],16,2)\n",
    "# w_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = 15608\n",
    "signal = sampled_df.iloc[record][['digit_label']+keys_MNIST_EP[8:12]][keys_MNIST_EP[8]]\n",
    "w_data = sliding_window_eeg(signal)\n",
    "w_data.shape\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(16, 15))\n",
    "fig.suptitle(f\"Record {record}: class label {sampled_df.iloc[record][['digit_label']]}\")\n",
    "w_data = w_data.reshape(9,32)\n",
    "axs[0].plot(signal)\n",
    "axs[0].set_title('Original Data')\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "for i in range(w_data.shape[0]):\n",
    "    axs[1].plot(w_data[i],linewidth=0.5)\n",
    "axs[1].plot(np.mean(w_data, axis=0),linewidth=2.5)\n",
    "axs[1].set_title('Windowed Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block is used to test downsampling with a convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = 1319\n",
    "series = sampled_df.iloc[record][['digit_label']+keys_MNIST_EP[8:12]]\n",
    "# Define a kernel (filter) of size 8\n",
    "kernel = np.ones(8) / 8  # Simple averaging filter\n",
    "# Function to apply convolution to a single series (pandas Series)\n",
    "def apply_convolution(series, kernel, stride=8):\n",
    "    # Perform convolution\n",
    "    convolved = np.convolve(series, kernel, mode='valid')\n",
    "    # Downsample to simulate stride\n",
    "    return pd.Series(convolved[::stride])\n",
    "\n",
    "series = series[keys_MNIST_EP[6:10]].apply(apply_convolution, kernel=kernel, stride=8)\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = 5082\n",
    "\n",
    "# inspect signal data from raw\n",
    "# psd_keys = [f\"{key}_PSD\" for key in keys_]\n",
    "# fig = hf.plot_4_signals(sampled_df.iloc[record][['digit_label']+psd_keys],\n",
    "#                     f\"RAW EEG series signal for class {sampled_df.iloc[record]['digit_label']}\"\n",
    "#                     ,y_labels=psd_keys,\n",
    "#                     digit_label=label,\n",
    "#                     norm=False,\n",
    "#                     fs=sample_rate,\n",
    "#                     x_units=\"sec\",\n",
    "#                     y_units=\"muV\")\n",
    "# inspect signal data from sampled or downsampled raw data\n",
    "\n",
    "fig = hf.plot_4_signals(sampled_df.iloc[record][['digit_label']+keys_MNIST_EP[8:12]],\n",
    "                    f\"RAW EEG series signal for class {sampled_df.iloc[record]['digit_label']}\"\n",
    "                    ,y_labels=keys_MNIST_EP[8:12],\n",
    "                    digit_label='digit_label',\n",
    "                    norm=True,\n",
    "                    fs=sample_rate,\n",
    "                    x_units=\"sec\",\n",
    "                    y_units=\"muV\")\n",
    "\n",
    "#fig = hf.plot_time_sequence(df.iloc[record]['EEGdata_T7_PSD'],title=f\"Class {df.iloc[record][label]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply notchfilter and bandpass filters to raw/sampled raw data. \n",
    "* No need to run this block if loaded the filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = sampled_df.copy() # sampled_df.copy()\n",
    "apply_filter = True\n",
    "for key in keys_MNIST_EP:\n",
    "    df_copy[f\"{key}_Freq\"] = pd.NA\n",
    "    df_copy[f\"{key}_PSD\"] = pd.NA\n",
    "\n",
    "for idx, row in tqdm(sampled_df.iterrows()):\n",
    "    if apply_filter:\n",
    "\n",
    "        filtered = hf.apply_notch_filter(row[keys_MNIST_EP],sample_rate,notch_freqs=notch_freqs,notch_widths=notch_widths)\n",
    "        filtered = hf.apply_butterworth_filter(filtered,sample_rate,lowcut,highcut,order=5)\n",
    "\n",
    "    else:\n",
    "        #filtered = row[keys_MNIST_IN]\n",
    "        filtered = hf.apply_notch_filter(row[keys_MNIST_EP],sample_rate,notch_freqs=notch_freqs,notch_widths=notch_widths)\n",
    "    window_length = 1 * sample_rate    # 2 seconds\n",
    "    for key in keys_MNIST_EP:\n",
    "        freq, PSD = welch(filtered[key], fs=sample_rate, nperseg=window_length)\n",
    "        filtered[f\"{key}_Freq\"] = freq\n",
    "        filtered[f\"{key}_PSD\"] = PSD\n",
    "    filtered[\"digit_label\"] = row['digit_label']\n",
    "    df_copy.loc[idx] = filtered\n",
    "\n",
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the correlation coefficents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(arr, corr_arr):\n",
    "    return np.corrcoef(arr, corr_arr)\n",
    "\n",
    "def subtract_series(arr, subtrahend):\n",
    "    return arr - subtrahend\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "example_data = sampled_df.iloc[record][keys_MNIST_EP]\n",
    "#print(type(example_data))\n",
    "#example_data['label'] = 0\n",
    "arr = np.stack(example_data.values)\n",
    "car = np.mean(arr, axis=0) \n",
    "baseline = np.mean(car[:16])\n",
    "car_corrected = car - baseline\n",
    "\n",
    "## subtract CAR from each channel\n",
    "example_car = example_data.apply(lambda x: subtract_series(x, car_corrected)) \n",
    "\n",
    "correlations_1 = [pearsonr(car_corrected, example_data[i])[0] for i in keys_MNIST_EP[8:12]]\n",
    "\n",
    "correlations_3 = [pearsonr(car_corrected, example_car[i])[0] for i in keys_MNIST_EP[8:12]]\n",
    "\n",
    "correlations_2 = [np.corrcoef(example_data[i], car_corrected)[0][1] for i in keys_MNIST_EP[8:12]]\n",
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(16, 15))\n",
    "\n",
    "# Plot original data\n",
    "axs[0].plot(np.array([np.linspace(0,256,256) for _ in range(4)]),np.stack(example_data[keys_MNIST_EP[8:12]]))\n",
    "axs[0].set_title('Original Data')\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_ylabel('Amplitude')\n",
    "\n",
    "# Plot CAR-referenced data\n",
    "axs[1].plot(np.array([np.linspace(0,256,256) for _ in range(4)]),np.stack(example_car[keys_MNIST_EP[8:12]].values))\n",
    "axs[1].set_title('CAR-Referenced Data')\n",
    "axs[1].set_xlabel('Time')\n",
    "axs[1].set_ylabel('Amplitude')\n",
    "\n",
    "# Plot correlation coefficients\n",
    "axs[2].bar(range(len(keys_MNIST_EP[8:12])), correlations_1)\n",
    "axs[2].set_title('Correlation Coefficients with CAR')\n",
    "axs[2].set_xlabel('Channel')\n",
    "axs[2].set_ylabel('Correlation Coefficient')\n",
    "axs[2].set_xticks(range(len(keys_MNIST_EP[8:12])))\n",
    "axs[2].set_xticklabels([f'Ch{i}' for i in keys_MNIST_EP[8:12]])\n",
    "\n",
    "# # Plot correlation coefficients\n",
    "axs[3].bar(range(len(keys_MNIST_EP[8:12])), correlations_3)\n",
    "axs[3].set_title('Correlation Coefficients with CAR')\n",
    "axs[3].set_xlabel('Channel')\n",
    "axs[3].set_ylabel('Correlation Coefficient')\n",
    "axs[3].set_xticks(range(len(keys_MNIST_EP[8:12])))\n",
    "axs[3].set_xticklabels([f'Ch{i}' for i in keys_MNIST_EP[8:12]])\n",
    "\n",
    "# # Plot correlation coefficients\n",
    "axs[4].bar(range(len(keys_MNIST_EP[8:12])), correlations_2)\n",
    "axs[4].set_title('Correlation Coefficients with CAR')\n",
    "axs[4].set_xlabel('Channel')\n",
    "axs[4].set_ylabel('Correlation Coefficient')\n",
    "axs[4].set_xticks(range(len(keys_MNIST_EP[8:12])))\n",
    "axs[4].set_xticklabels([f'Ch{i}' for i in keys_MNIST_EP[8:12]])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data['label'] = 0\n",
    "example_car['label'] = 0\n",
    "fig = hf.plot_4_signals(example_data[['label']+keys_MNIST_EP[8:12]],f\"RAW EEG series signal for class {sampled_df.iloc[record]['digit_label']}\"\n",
    "                    ,y_labels=keys_MNIST_EP[8:12],\n",
    "                    digit_label='digit_label',\n",
    "                    norm=True,\n",
    "                    fs=sample_rate,\n",
    "                    x_units=\"sec\",\n",
    "                    y_units=\"muV\")\n",
    "\n",
    "fig = hf.plot_4_signals(example_car[['label']+keys_MNIST_EP[8:12]],f\"RAW EEG series signal for class {sampled_df.iloc[record]['digit_label']}\"\n",
    "                    ,y_labels=keys_MNIST_EP[8:12],\n",
    "                    digit_label='digit_label',\n",
    "                    norm=True,\n",
    "                    fs=sample_rate,\n",
    "                    x_units=\"sec\",\n",
    "                    y_units=\"muV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_snr(signal_reduced, signal_sample):\n",
    "    \"\"\"\n",
    "    Calculate the Signal-to-Noise Ratio (SNR) given a noise-reduced signal and a sample signal.\n",
    "\n",
    "    Parameters:\n",
    "    - signal_reduced: ndarray of the noise-reduced signal.\n",
    "    - signal_sample: ndarray of the sample signal.\n",
    "\n",
    "    Returns:\n",
    "    - snr: The Signal-to-Noise Ratio in decibels (dB).\n",
    "    \"\"\"\n",
    "    # Calculate the noise as the difference between the sample and noise-reduced signal\n",
    "    noise = signal_sample - signal_reduced\n",
    "\n",
    "    # Calculate the power of the signal (mean squared value)\n",
    "    signal_power = np.mean(signal_reduced ** 2)\n",
    "\n",
    "    # Calculate the power of the noise (mean squared value)\n",
    "    noise_power = np.mean(noise ** 2)\n",
    "\n",
    "    # Calculate the SNR in decibels (dB)\n",
    "    snr = 10 * np.log10(signal_power / noise_power)\n",
    "\n",
    "    return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = []\n",
    "for i in range(len(keys_MNIST_EP[8:12])):\n",
    "    x = example_car[keys_MNIST_EP[8:12]][i]\n",
    "    s = example_data[keys_MNIST_EP[8:12]][i]\n",
    "    snr.append(calculate_snr(x,s))\n",
    "    \n",
    "print(np.mean(snr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1177it [00:00, 5929.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: mean SNR 0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [00:00, 5905.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: mean SNR 0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1132it [00:00, 5049.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 2: mean SNR 0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1102it [00:00, 6277.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 3: mean SNR 0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1096it [00:00, 6181.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: mean SNR 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1178it [00:00, 6244.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 5: mean SNR 0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1169it [00:00, 5466.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 6: mean SNR 0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1195it [00:00, 6309.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 7: mean SNR 0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1113it [00:00, 6173.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 8: mean SNR 0.382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1148it [00:00, 5838.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 9: mean SNR 0.280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for class_label in class_labels:\n",
    "    class_df = sampled_df[sampled_df[label]==class_label]\n",
    "    snr = []\n",
    "    for idx, row in tqdm(class_df.iterrows()):\n",
    "        for key in keys_MNIST_EP[8:12]:\n",
    "            x = row[key] - (row[key] -row['erp'])\n",
    "            s = row[key]\n",
    "            snr.append(calculate_snr(x,s))\n",
    "    print(f\"Class {class_label}: mean SNR {np.mean(snr):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_df = None\n",
    "#sampled_df = df_copy.copy()\n",
    "df_copy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = sampled_df.copy()\n",
    "\n",
    "for key in keys_MNIST_EP:\n",
    "    df_copy[f\"{key}_corr\"] = pd.NA\n",
    "df_copy[f\"erp\"] = pd.NA\n",
    "\n",
    "for idx, row in tqdm(sampled_df.iterrows()):\n",
    "    corr_data = row[keys_MNIST_EP]\n",
    "    arr = np.stack(corr_data.values)\n",
    "    # Calculate ERP\n",
    "    car = np.mean(arr, axis=0)\n",
    "    # Baseline correction (using first 125 ms as baseline)\n",
    "    baseline = np.mean(car[:16])\n",
    "    car_corrected = car - baseline\n",
    "\n",
    "    for key in keys_MNIST_EP:\n",
    "        #car_subtracted = corr_data[key] - car_corrected\n",
    "        #correlation = np.corrcoef(car_subtracted, car_corrected)[0, 1]\n",
    "        correlation = np.corrcoef(corr_data[key], car_corrected)[0, 1]\n",
    "        row[f\"{key}_corr\"] = correlation\n",
    "    #corr_data[label] = row[label]\n",
    "    row['erp'] = car_corrected\n",
    "\n",
    "    df_copy.loc[idx] = row\n",
    "\n",
    "df_copy.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampled_df = None\n",
    "df_copy['digit_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_keys_ = ['EEGdata_T7_corr','EEGdata_P7_corr','EEGdata_T8_corr','EEGdata_P8_corr']\n",
    "df_copy['corr_mean_core'] = df_copy[corr_keys_].mean(axis=1)\n",
    "corr_keys_ = [f\"{key}_corr\" for key in keys_MNIST_EP]\n",
    "df_copy['corr_mean_all'] = df_copy[corr_keys_].mean(axis=1)\n",
    "#df_copy.dropna(axis=1, inplace=True)\n",
    "df_copy.info()\n",
    "print(df_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['corr_mean_core'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    1195\n",
      "5    1178\n",
      "0    1177\n",
      "6    1169\n",
      "9    1148\n",
      "2    1132\n",
      "8    1113\n",
      "3    1102\n",
      "4    1096\n",
      "1    1086\n",
      "Name: digit_label, dtype: int64\n",
      "11396\n"
     ]
    }
   ],
   "source": [
    "fraction = 1\n",
    "sampled_indexes = df_copy[df_copy['corr_mean_core'] > 0.2].groupby(label).apply(lambda x: x.sample(frac=fraction)).index.get_level_values(1).tolist()\n",
    "sampled_df = df_copy.loc[sampled_indexes]\n",
    "#sampled_df.info()\n",
    "print(sampled_df[label].value_counts())\n",
    "print(sampled_df[label].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "feature_data = []\n",
    "label_data = []\n",
    "for class_label in class_labels:\n",
    "    class_df = sampled_df[sampled_df[label]==class_label]\n",
    "    for idx, row in tqdm(class_df.iterrows()):\n",
    "        for key in keys_:\n",
    "            w_data = sliding_window_eeg(row[key])\n",
    "            feature_data.append(np.array(w_data))\n",
    "            label_data.append(to_categorical(int(class_label),num_classes=len(class_labels)))\n",
    "\n",
    "train_data = np.array(feature_data)\n",
    "labels = np.array(label_data).astype(np.uint8)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_out = {'x_train':x_train,'x_test':x_test,'y_train':y_train,'y_test':y_test}\n",
    "prefix = [\"data_4ch_90_32_4_\",\"fil_corr_\",\"data_4ch_epoch_filtered_324_0-2\",\"data_4ch_epoch_filtered_324_0-85\"]\n",
    "print(f\"writing {root_dir}/{prefix[3]}{output_file}\")\n",
    "data_out = {'x_train':x_train,'x_test':x_test,'y_train':y_train,'y_test':y_test} #{'x_test':train_data,'y_test':labels}\n",
    "with open(f\"{root_dir}/{prefix[3]}{output_file}\", 'wb') as f:\n",
    "    pickle.dump(data_out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load the filtered/sampled/downsampled data to file, change the prefix as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHANGE FILE NAME FOR TEST / TRAIN\n",
    "prefix = [\"filtered_bp_corr_\",\"fil_corr_\",\"epoch_filtered_\",\"epoch_filtered_-car_\",\"epoch_filtered_rcar_\"]\n",
    "print(f\"writing {root_dir}/{prefix[4]}{output_file}\")  # filtered_{output_file}\n",
    "with open(f\"{root_dir}/{prefix[4]}{output_file}\", 'wb') as f:\n",
    "    pickle.dump(df_copy, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** reading file Datasets/MindBigData MNIST of Brain Digits/MNIST_EP/epoch_filtered_-car_train_MindBigData2022_MNIST_EP.pkl\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38509 entries, 16632 to 28018\n",
      "Data columns (total 60 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   digit_label       38509 non-null  int64  \n",
      " 1   EEGdata_AF3       38509 non-null  object \n",
      " 2   EEGdata_AF4       38509 non-null  object \n",
      " 3   EEGdata_F7        38509 non-null  object \n",
      " 4   EEGdata_F8        38509 non-null  object \n",
      " 5   EEGdata_F3        38509 non-null  object \n",
      " 6   EEGdata_F4        38509 non-null  object \n",
      " 7   EEGdata_FC5       38509 non-null  object \n",
      " 8   EEGdata_FC6       38509 non-null  object \n",
      " 9   EEGdata_T7        38509 non-null  object \n",
      " 10  EEGdata_T8        38509 non-null  object \n",
      " 11  EEGdata_P7        38509 non-null  object \n",
      " 12  EEGdata_P8        38509 non-null  object \n",
      " 13  EEGdata_O1        38509 non-null  object \n",
      " 14  EEGdata_O2        38509 non-null  object \n",
      " 15  EEGdata_AF3_Freq  38509 non-null  object \n",
      " 16  EEGdata_AF3_PSD   38509 non-null  object \n",
      " 17  EEGdata_AF4_Freq  38509 non-null  object \n",
      " 18  EEGdata_AF4_PSD   38509 non-null  object \n",
      " 19  EEGdata_F7_Freq   38509 non-null  object \n",
      " 20  EEGdata_F7_PSD    38509 non-null  object \n",
      " 21  EEGdata_F8_Freq   38509 non-null  object \n",
      " 22  EEGdata_F8_PSD    38509 non-null  object \n",
      " 23  EEGdata_F3_Freq   38509 non-null  object \n",
      " 24  EEGdata_F3_PSD    38509 non-null  object \n",
      " 25  EEGdata_F4_Freq   38509 non-null  object \n",
      " 26  EEGdata_F4_PSD    38509 non-null  object \n",
      " 27  EEGdata_FC5_Freq  38509 non-null  object \n",
      " 28  EEGdata_FC5_PSD   38509 non-null  object \n",
      " 29  EEGdata_FC6_Freq  38509 non-null  object \n",
      " 30  EEGdata_FC6_PSD   38509 non-null  object \n",
      " 31  EEGdata_T7_Freq   38509 non-null  object \n",
      " 32  EEGdata_T7_PSD    38509 non-null  object \n",
      " 33  EEGdata_T8_Freq   38509 non-null  object \n",
      " 34  EEGdata_T8_PSD    38509 non-null  object \n",
      " 35  EEGdata_P7_Freq   38509 non-null  object \n",
      " 36  EEGdata_P7_PSD    38509 non-null  object \n",
      " 37  EEGdata_P8_Freq   38509 non-null  object \n",
      " 38  EEGdata_P8_PSD    38509 non-null  object \n",
      " 39  EEGdata_O1_Freq   38509 non-null  object \n",
      " 40  EEGdata_O1_PSD    38509 non-null  object \n",
      " 41  EEGdata_O2_Freq   38509 non-null  object \n",
      " 42  EEGdata_O2_PSD    38509 non-null  object \n",
      " 43  EEGdata_AF3_corr  38509 non-null  object \n",
      " 44  EEGdata_AF4_corr  38509 non-null  object \n",
      " 45  EEGdata_F7_corr   38509 non-null  object \n",
      " 46  EEGdata_F8_corr   38509 non-null  object \n",
      " 47  EEGdata_F3_corr   38509 non-null  object \n",
      " 48  EEGdata_F4_corr   38509 non-null  object \n",
      " 49  EEGdata_FC5_corr  38509 non-null  object \n",
      " 50  EEGdata_FC6_corr  38509 non-null  object \n",
      " 51  EEGdata_T7_corr   38509 non-null  object \n",
      " 52  EEGdata_T8_corr   38509 non-null  object \n",
      " 53  EEGdata_P7_corr   38509 non-null  object \n",
      " 54  EEGdata_P8_corr   38509 non-null  object \n",
      " 55  EEGdata_O1_corr   38509 non-null  object \n",
      " 56  EEGdata_O2_corr   38509 non-null  object \n",
      " 57  erp               38509 non-null  object \n",
      " 58  corr_mean_core    38509 non-null  float64\n",
      " 59  corr_mean_all     38509 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(57)\n",
      "memory usage: 17.9+ MB\n",
      "3    3950\n",
      "9    3917\n",
      "5    3916\n",
      "6    3868\n",
      "8    3861\n",
      "0    3845\n",
      "2    3809\n",
      "1    3798\n",
      "7    3780\n",
      "4    3765\n",
      "Name: digit_label, dtype: int64\n",
      "Index(['digit_label', 'EEGdata_AF3', 'EEGdata_AF4', 'EEGdata_F7', 'EEGdata_F8',\n",
      "       'EEGdata_F3', 'EEGdata_F4', 'EEGdata_FC5', 'EEGdata_FC6', 'EEGdata_T7',\n",
      "       'EEGdata_T8', 'EEGdata_P7', 'EEGdata_P8', 'EEGdata_O1', 'EEGdata_O2',\n",
      "       'EEGdata_AF3_Freq', 'EEGdata_AF3_PSD', 'EEGdata_AF4_Freq',\n",
      "       'EEGdata_AF4_PSD', 'EEGdata_F7_Freq', 'EEGdata_F7_PSD',\n",
      "       'EEGdata_F8_Freq', 'EEGdata_F8_PSD', 'EEGdata_F3_Freq',\n",
      "       'EEGdata_F3_PSD', 'EEGdata_F4_Freq', 'EEGdata_F4_PSD',\n",
      "       'EEGdata_FC5_Freq', 'EEGdata_FC5_PSD', 'EEGdata_FC6_Freq',\n",
      "       'EEGdata_FC6_PSD', 'EEGdata_T7_Freq', 'EEGdata_T7_PSD',\n",
      "       'EEGdata_T8_Freq', 'EEGdata_T8_PSD', 'EEGdata_P7_Freq',\n",
      "       'EEGdata_P7_PSD', 'EEGdata_P8_Freq', 'EEGdata_P8_PSD',\n",
      "       'EEGdata_O1_Freq', 'EEGdata_O1_PSD', 'EEGdata_O2_Freq',\n",
      "       'EEGdata_O2_PSD', 'EEGdata_AF3_corr', 'EEGdata_AF4_corr',\n",
      "       'EEGdata_F7_corr', 'EEGdata_F8_corr', 'EEGdata_F3_corr',\n",
      "       'EEGdata_F4_corr', 'EEGdata_FC5_corr', 'EEGdata_FC6_corr',\n",
      "       'EEGdata_T7_corr', 'EEGdata_T8_corr', 'EEGdata_P7_corr',\n",
      "       'EEGdata_P8_corr', 'EEGdata_O1_corr', 'EEGdata_O2_corr', 'erp',\n",
      "       'corr_mean_core', 'corr_mean_all'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "prefix = [\"filtered_bp_\",\"fil_corr_\",\"epoch_filtered_\",\"epoch_filtered_-car_\",\"epoch_filtered_rcar_\"]\n",
    "print(f\"** reading file {root_dir}/{prefix[3]}{output_file}\")\n",
    "df_copy = pd.read_pickle(f\"{root_dir}/{prefix[3]}{output_file}\")\n",
    "df_copy.info()\n",
    "print(df_copy[label].value_counts())\n",
    "print(df_copy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USe to display/inspect signal data after filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = sampled_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = 1010\n",
    "\n",
    "\n",
    "fig = hf.plot_4_signals(df_copy.iloc[record][['digit_label']+keys_],\n",
    "                    f\"RAW EEG series signal for class {df_copy.iloc[record]['digit_label']}\"\n",
    "                    ,y_labels=keys_,\n",
    "                    digit_label='digit_label',\n",
    "                    norm=False,\n",
    "                    fs=sample_rate,\n",
    "                    x_units=\"sec\",\n",
    "                    y_units=\"muV\")\n",
    "plt.show()\n",
    "\n",
    "#fig = hf.plot_time_sequences(df_copy.iloc[record][keys_+['erp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq,psd = welch(df_copy.iloc[record]['EEGdata_T8'], fs=sample_rate, nperseg=32, noverlap=4)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(16, 4), sharex=True)\n",
    "#axs.plot(freq,psd)\n",
    "axs.semilogy(freq,psd)\n",
    "#axs.psd(df_copy.iloc[record]['EEGdata_T8'], NFFT=64, Fs=sample_rate, scale_by_freq=True)\n",
    "axs.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and subplots\n",
    "r, c = 2, 2\n",
    "fig, axs = plt.subplots(r, c, figsize=(16, 8), sharex=True)\n",
    "fig.suptitle(f\"Power signal for class {df_copy.iloc[record][label]}\", fontsize=16)\n",
    "cnt = 0\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "\n",
    "        #freq,psd = welch(filtered[cnt], fs=sample_rate, nperseg=window_length) #64 #, noverlap=32)\n",
    "        #freq = df_copy.iloc[record][f\"{keys_[cnt]}_Freq\"]\n",
    "        #psd = df_copy.iloc[record][f\"{keys_[cnt]}_PSD\"]\n",
    "        axs[i,j].plot(freq,psd)\n",
    "        axs[i,j].grid(True)\n",
    "        axs[i,j].set_title(f\"{keys_[cnt]}\", fontsize=12)\n",
    "        cnt += 1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_size = 200\n",
    "random_state = 23\n",
    "train_data = []\n",
    "label_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a kernel (filter) of size 8\n",
    "kernel = np.ones(8) / 8  # Simple averaging filter\n",
    "use_downsample = False\n",
    "slice = 0 #(64,192)\n",
    "## raw signals\n",
    "# sub_df = df[df['digit_label']!= -1]\n",
    "## filtered signals\n",
    "#sub_df = df_copy[df_copy['digit_label']!= -1]\n",
    "\n",
    "for idx, record in tqdm(df_copy.iterrows()):\n",
    "    label_data.append(to_categorical(record[label],num_classes=len(class_labels)))\n",
    "    selected_features = []\n",
    "    #key_features = []\n",
    "    for key in keys_:\n",
    "        if use_downsample:\n",
    "            downsample = np.convolve(record[f\"{key}\"], kernel, mode=\"valid\")\n",
    "            downsample = downsample[::8]\n",
    "            #selected_features.append(record[f\"{key}\"])    ## each sample is ~8ms at 128 Hz @2 seconds = 256 samples, drop the first ~250msec = 30 samples\n",
    "            selected_features.append(downsample)\n",
    "        else:\n",
    "            if slice == 0:\n",
    "                selected_features.append(record[f\"{key}\"])    ## each sample is ~8ms at 128 Hz @2 seconds = 256 samples, drop the first ~250msec = 30 samples\n",
    "            else:\n",
    "                selected_features.append(record[f\"{key}\"][slice[0]:slice[1]])\n",
    "\n",
    "    #selected_features = StandardScaler().fit_transform(selected_features)\n",
    "    #train_data.append(np.array(selected_features).reshape(len(selected_features),len(record[f\"{key}\"]),1))\n",
    "    train_data.append(np.array(selected_features).T)\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label_data = np.array(label_data).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(label_data.shape)\n",
    "\n",
    "np.save(f\"{root_dir}/training_{dataset}_corr_93T_signals\",train_data)\n",
    "np.save(f\"{root_dir}/training_{dataset}_corr_93T_signals_labels\",label_data)\n",
    "\n",
    "# np.save(f\"{root_dir}/testing_MNIST_EP_signals\",train_data)\n",
    "# np.save(f\"{root_dir}/testing_MNIST_EP_signals_labels\",label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adv-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
